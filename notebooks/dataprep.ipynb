{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5689be8b",
   "metadata": {},
   "source": [
    "# Tratamento Inicial de Dados\n",
    "\n",
    "Neste tratamento de dados inicial, apenas é feita a **transformação e normalização de dados do tipo string**.  \n",
    "\n",
    "- **O que é feito:**  \n",
    "  - Normalização de colunas categóricas (`strip`, `upper`/`lower`)  \n",
    "  - Remoção de acentos usando `unidecode`  \n",
    "  - Conversão de colunas para tipo `category` para economizar memória  \n",
    "\n",
    "- **O que não é feito:**  \n",
    "  - Tratamento de valores ausentes (NaNs)  \n",
    "  - Tratamento de outliers  \n",
    "\n",
    "> Você pode verificar que o **número de NaNs não se altera** após este processo.\n",
    "\n",
    "No final, o dataset é salvo no formato **pickle** para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2edf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from unidecode import unidecode\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c1b76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acidentes2017_todas_causas_tipos.zip', 'acidentes2018_todas_causas_tipos.zip', 'acidentes2019_todas_causas_tipos.zip', 'acidentes2020_todas_causas_tipos.zip', 'acidentes2021_todas_causas_tipos.zip', 'acidentes2022_todas_causas_tipos.zip', 'acidentes2023_todas_causas_tipos.zip', 'acidentes2024_todas_causas_tipos.zip']\n"
     ]
    }
   ],
   "source": [
    "dirpath = os.path.join('..','data','raw')\n",
    "print(os.listdir(dirpath))\n",
    "data  = [pd.read_csv(os.path.join(dirpath,file),encoding='latin1',sep=';') for file in os.listdir(dirpath)]\n",
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07f0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizo o nomes das colunas\n",
    "data.columns = data.columns.str.strip().str.lower()\n",
    "data.columns = [unidecode(col) for col in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ea9b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A coluna latitude for forçada para string\n",
      "A coluna longitude for forçada para string\n"
     ]
    }
   ],
   "source": [
    "def is_mixed(col):\n",
    "    return len(set(type(x) for x in col if pd.notna(x)))>1\n",
    "# Converte dados mistos em strings, Deveria também tratar possiveis Nans, mas aqui apenas as colunas longitude e latitude tem valores mistos, \n",
    "# e como elas não tem Nans, eu apliquei em toda a coluna sem risco\n",
    "for c in data.columns:\n",
    "    if is_mixed(data[c]):\n",
    "        print(f'A coluna {c} for forçada para string')\n",
    "        data[c] = data[c].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15855615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alteração do nome data_inversa para data, e limpeza do nome das colunas\n",
    "data.columns = data.columns.str.strip().str.lower()\n",
    "data.rename(columns={'data_inversa':'data'},inplace=True)\n",
    "# é possivel obter horario e dia da semana a partir da coluna data, então eliminei colunas horario e dia da semana\n",
    "data['data'] = pd.to_datetime(data['data']+' '+data['horario'])\n",
    "data.drop(['horario','dia_semana'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2527492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A coluna id foi forçada para Int64\n",
      "A coluna pesid foi forçada para Int64\n",
      "A coluna idade foi forçada para Int64\n",
      "A coluna ilesos foi forçada para Int64\n",
      "A coluna feridos_leves foi forçada para Int64\n",
      "A coluna feridos_graves foi forçada para Int64\n",
      "A coluna mortos foi forçada para Int64\n",
      "A coluna ano_fabricacao_veiculo foi forçada para Int64\n",
      "A coluna id_veiculo foi forçada para Int64\n"
     ]
    }
   ],
   "source": [
    "# Testa se todos os valores(excluindo Nans) são inteiros, se sim força conversão para Int64\n",
    "def is_integer(col):\n",
    "    notna = col[col.notna()]\n",
    "    return (notna % 1 == 0).all()\n",
    "integers = ['id','pesid','idade','ilesos','feridos_leves','feridos_graves','mortos','ano_fabricacao_veiculo','id_veiculo']\n",
    "for i in integers:\n",
    "    if is_integer(data[i]):\n",
    "        print(f'A coluna {i} foi forçada para Int64')\n",
    "        data[i] = data[i].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe59c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformo o id e pesid para inteiros\n",
    "data['id'] = data['id'].astype('Int64')\n",
    "data['pesid'] = data['pesid'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2177e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A coluna uf foi convertida para category(uppercase)\n",
      "A coluna municipio foi convertida para category(uppercase)\n",
      "A coluna delegacia foi convertida para category(uppercase)\n",
      "A coluna regional foi convertida para category(uppercase)\n",
      "A coluna uop foi convertida para category(uppercase)\n",
      "A coluna causa_principal foi convertida para category(lowercase)\n",
      "A coluna causa_acidente foi convertida para category(lowercase)\n",
      "A coluna tipo_acidente foi convertida para category(lowercase)\n",
      "A coluna classificacao_acidente foi convertida para category(lowercase)\n",
      "A coluna fase_dia foi convertida para category(lowercase)\n",
      "A coluna sentido_via foi convertida para category(lowercase)\n",
      "A coluna condicao_metereologica foi convertida para category(lowercase)\n",
      "A coluna tipo_pista foi convertida para category(lowercase)\n",
      "A coluna tracado_via foi convertida para category(lowercase)\n",
      "A coluna uso_solo foi convertida para category(lowercase)\n",
      "A coluna sexo foi convertida para category(lowercase)\n",
      "A coluna tipo_envolvido foi convertida para category(lowercase)\n",
      "A coluna estado_fisico foi convertida para category(lowercase)\n",
      "A coluna tipo_veiculo foi convertida para category(lowercase)\n",
      "A coluna marca foi convertida para category(lowercase)\n"
     ]
    }
   ],
   "source": [
    "# Normalização de colunas categoricas que são strings\n",
    "cat_upper = ['uf',\n",
    "            'municipio',\n",
    "            'delegacia',\n",
    "            'regional',\n",
    "            'uop'\n",
    "]\n",
    "for cat in cat_upper:\n",
    "    data[cat] = data[cat].str.strip().str.upper()\n",
    "    data[cat] = data[cat].map(lambda s: unidecode(s) if pd.notna(s) else s)\n",
    "    data[cat] = data[cat].astype('category')\n",
    "    print(f'A coluna {cat} foi convertida para category(uppercase)')\n",
    "cat_lower = ['causa_principal',\n",
    "            'causa_acidente',\n",
    "            'tipo_acidente',\n",
    "            'classificacao_acidente',\n",
    "            'fase_dia',\n",
    "            'sentido_via',\n",
    "            'condicao_metereologica',\n",
    "            'tipo_pista',\n",
    "            'tracado_via',\n",
    "            'uso_solo',\n",
    "            'sexo',\n",
    "            'tipo_envolvido',\n",
    "            'estado_fisico',\n",
    "            'tipo_veiculo',\n",
    "            'marca'\n",
    "]\n",
    "for cat in cat_lower:\n",
    "    data[cat] = data[cat].str.strip().str.lower()\n",
    "    data[cat] = data[cat].map(lambda s: unidecode(s) if pd.notna(s) else s)\n",
    "    data[cat] = data[cat].astype('category')\n",
    "    print(f'A coluna {cat} foi convertida para category(lowercase)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7647212",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['km'] = data['km'].str.replace(',','.').astype('float')\n",
    "data['latitude'] = data['latitude'].str.strip().str.replace(',','.').astype(float)\n",
    "data['longitude'] = data['longitude'].str.strip().str.replace(',','.').astype(float)\n",
    "data['br'] = data['br'].astype('category')\n",
    "data['ordem_tipo_acidente'] = data['ordem_tipo_acidente'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "513c9b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(os.path.join('..','data','processed','datatran.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
